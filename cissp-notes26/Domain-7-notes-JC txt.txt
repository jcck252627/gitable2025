
‚Ä¢ Domain 1: Security and Risk Management	
‚Ä¢ Domain 2: Asset Security
‚Ä¢ Domain 3: Security Architecture and Engineering	
‚Ä¢ Domain 4: Communication and Network Security
‚Ä¢ Domain 5: Identity and Access Management (IAM)
‚Ä¢ Domain 6: Security Assessment and Testing
‚Ä¢ Domain 7: Security Operations		***************************************************
‚Ä¢ Domain 8: Software Development Security










D7
**********************************************************
A high number of emergency change requests can be an indicator of insufficient or ineffective planning and control within the change management process. Emergency changes are typically unplanned and urgent, suggesting that the standard change request procedures may not be adequately addressing the needs of the organization or that changes are not being anticipated and managed proactively.

The MOST important aspect of configuration management is ensuring that all configuration changes are documented and approved. Configuration Management (CM) primarily focuses on establishing and maintaining consistency in a system's performance, functional, and physical attributes with its requirements, design, and operational information. Therefore, any changes to the system configuration need to be documented, reviewed, and approved. This practice helps avoid unnecessary or harmful changes, allows for the tracking of modifications, and aids in the ability to roll back changes if they cause problems. 

When we list the Minimum Operating Requirements (MOR) for a system in our BIA (Business Impact Analysis), what should it contain?

The minimum hardware and software specifications required to run the system: The Minimum Operating Requirements (MOR) refer to the fundamental conditions or resources necessary to keep a system, such as a computer network, software, or device, operating at a basic level. This would include the hardware and software specifications needed for the system to function. Hardware might entail specific processors, RAM, or other physical components, while software might refer to necessary operating systems, drivers, or applications. When conducting a Business Impact Analysis (BIA), it is vital to understand these requirements, as they help determine the minimum levels of service and resources needed to maintain critical operations during a disruption or disaster. The incorrect answers: While the minimum amount of data storage is a vital consideration in overall system planning and operation, it does not typically fall under the definition of Minimum Operating Requirements (MOR). Data storage requirements may vary widely based on the nature of the system and the tasks it's used for. In the context of a BIA, it's important to understand storage needs, especially regarding critical data, but this would usually be separate from the MOR, which focuses on the necessary conditions to operate the system at a basic level. The minimum number of users required to access a system is typically not considered part of the Minimum Operating Requirements (MOR). The MOR primarily concerns the hardware and software requirements necessary for a system to function, not the number of users who can or should access it. User count may factor into capacity planning, role assignments, or usage scenarios but is not directly linked to the essential technical requirements needed to keep the system operational. The minimum security controls required to protect the system: While implementing sufficient security controls is crucial for the safe operation of any system, these do not typically fall under the category of Minimum Operating Requirements (MOR). The MOR focuses on what is required for the system to operate at a basic level. Although security controls are important, they are generally classified under different aspects of system administration, such as information security or cybersecurity protocols. In a Business Impact Analysis (BIA), while security controls would indeed be assessed, they would typically be treated as separate considerations from the MOR.

Which of the following statements best describes the roles and responsibilities in communicating and responding to a significant cyberattack?
 The IT team communicates the severity of the situation to their immediate superior, who then disseminates the information as per the disaster response plan is the most accurate answer because it follows the established protocol for disaster communication in an organization. The IT team's primary responsibility in a crisis is to mitigate and contain the situation. They inform their immediate superiors about the situation's severity, who then, based on the predefined disaster response plan, communicate the details to the necessary stakeholders like HR, Legal, Board of Directors, and others. This keeps the lines of communication clear and ensures that the right information is delivered to the right people at the right time. 

software update processes ...
 very first step is to identify the need for the update. This could be due to various reasons such as fixing security vulnerabilities, improving performance, adding new features, or addressing software bugs. Identifying the need for an update typically involves monitoring software performance, getting feedback from users, and staying informed about new security threats that could affect the software. It's the basis for all subsequent actions and without this step, one wouldn't know what to update or why it needs to be updated.
 
 : Installing anti-shimmer technology on credit card readers: A shimmer attack involves inserting a small device, known as a shimmer, into a credit or debit card reader, particularly an ATM or gas pump, to steal data from the card's chip. This attack is more advanced than the previous skimming attacks because it targets the chip on the card instead of the magnetic strip, which makes the attack harder to detect. Anti-shimmer technology specifically counters this threat
 

Communications team: Following the formal declaration of a disaster and the initial triage team assessment, the Communications team would most likely be called upon next. They play a crucial role in managing internal and external communications, informing stakeholders, coordinating with emergency services, issuing public statements, and keeping employees updated on the situation. Effective communication is critical in managing the aftermath of a disaster and in the recovery process. The incorrect answers: Facilities management: While Facilities management is important in addressing the physical impact of a disaster on the organization's property, the immediate next step after triage typically involves communication rather than facility repair or management. IT Services department: The IT Services department will be essential in restoring technological infrastructure and systems, but they are more likely to be called upon after the initial communication phase unless the disaster specifically impacted IT systems directly. Legal department: The Legal department will be important in navigating any legal implications of the disaster and for advising on regulatory reporting requirements. However, they are generally not the next team called upon immediately following the triage, unless there are immediate legal considerations that need to be addressed.

 Both internal and external users. To accurately measure the success of an incident handling process, it's helpful to gather feedback from both internal and external users. Internal users can provide insight into the efficiency of the process, while external users can offer perspective on how incidents were communicated and resolved from their end. The incorrect answers: All business units: While feedback from all business units can be valuable, it's only part of the picture. Including external users provides a more comprehensive understanding of the process's effectiveness. External investors, shareholders, and stakeholders: These parties are typically not directly involved in incident handling and are therefore less suitable for gauging the success of the process. Internal users only: While internal users can provide important feedback, it's also valuable to gain perspective from external users who interact with the organization's systems or services.

In our digital forensics, which of these should NEVER happen?
Modification of digital evidence: The integrity of digital evidence is of paramount importance in digital forensics. Modifying the digital evidence means altering the original data, which can potentially lead to wrongful conclusions. The accepted principle in handling digital evidence is to make a bit-by-bit copy of the original data (usually a hard disk or memory storage) and perform investigations on the copy. This ensures that the original data is preserved and untouched. Modifying digital evidence not only undermines the integrity of the investigation but could also have legal consequences. It should never happen in digital forensics. The incorrect answers: The destruction of physical evidence: While this might initially seem correct, there are scenarios where the destruction of physical evidence is necessary in digital forensics. For instance, once the relevant digital evidence has been extracted and properly documented, certain physical devices might need to be destroyed due to company policies, especially if they contain sensitive data. In some cases, authorities might also destroy physical evidence after a case is closed to prevent misuse of the data. While it's essential to handle physical evidence carefully, its destruction isn't always to be avoided. Taint of digital evidence: The phrase 'taint of digital evidence' might be interpreted as introducing or incorporating irrelevant or misleading data into the evidence. This is generally undesirable, as it could confuse the investigation or lead to false conclusions. However, unlike modification of digital evidence, this doesn't necessarily violate the integrity of the original evidence. It's more of an issue of poor practice or handling, which while should be avoided, doesn't hold the same level of prohibition as the modification of digital evidence. Collection of digital evidence: This is actually a crucial part of digital forensics. Investigators need to collect digital evidence in a forensically sound manner to help solve the case. This involves acquiring data from various digital sources while maintaining the integrity of the evidence. Without the collection of digital evidence, digital forensics would be impossible. Therefore, this is not only something that should happen, but it is a key aspect of the process.

 Gather information from different sources. Gathering information from different sources provides a more comprehensive view of the network, which can enhance the efficiency and effectiveness of Security Information and Event Management (SIEM) systems in correlating events and detecting attacks. This approach provides a holistic view of the network and enables the SIEM to identify patterns and connections that may not be visible when looking at data from individual sources. For example, gathering info from a router and honeypot devices may allow us to know exactly what an attacker is seeking, versus just router logs. The incorrect answers: Gather information only from web servers: This approach would limit the visibility of the SIEM to just the web servers, possibly missing attacks targeting other parts of the infrastructure. Gather information only from network devices such as routers and firewalls: While these devices are crucial for network security, they should not be the sole source of information for a SIEM. Attacks can also target servers, applications, and other parts of the network. Gather information only from application servers: This approach would limit the visibility of the SIEM to just application servers, missing attacks that may target other parts of the network.

Cold site: A cold site is the cheapest solution for an alternate site where specialized hardware is available in the event of a disaster. Cold sites typically provide only the basic physical environment for a data center, such as space, power, and connectivity, but not the actual hardware or data replication. The company would be responsible for installing and configuring their specialized hardware at the cold site in the event of a disaster, which allows for cost savings compared to more fully-equipped alternatives. The incorrect answers: Hot site: A hot site is a fully equipped and operational data center that includes not only the physical space but also the hardware, software, and live data replication necessary to assume operations quickly after a disaster. Hot sites are the most expensive alternate site solutions due to the high level of readiness and maintenance required. Warm site: A warm site is a compromise between a hot site and a cold site, providing some level of pre-installed equipment, but not the full real-time data replication of a hot site. Warm sites are less expensive than hot sites but more costly than cold sites because they include more infrastructure. Mobile site: A mobile site typically consists of a portable structure that can be shipped to a location and set up quickly in the event of a disaster. These sites are equipped with necessary hardware and connectivity solutions, making them more expensive than a cold site, which does not include such pre-installed equipment.

The data owner: Bob should notify the data owner first. In the context of incident response, the data owner is the individual responsible for the data that has been compromised and is in the best position to understand the significance of the breach. The data owner can assess the impact, help determine which customers are affected, and play a crucial role in coordinating the appropriate response, including customer notification and regulatory reporting. The incorrect answers: The Information Security steering committee: While the Information Security steering committee is an important body that should be informed about security incidents, notifying the data owner first is more critical for immediate response actions. The customers who were compromised: Notifying customers is a necessary step, but it typically comes after an initial assessment and containment of the breach. The data owner, along with the incident response team, will determine the timing and content of communication to customers. The regulatory agencies that govern our sector: Regulatory agencies are often required to be notified in the event of certain types of breaches; however, they are typically not the first point of contact. The immediate response involves assessment and containment, followed by notification to regulatory agencies as dictated by applicable laws and regulations, after the initial internal actions are taken.

Audit logs. Audit logs record events as they happen and can then be analyzed later to identify significant events or anomalies. They also meet the requirement of being passive, as they typically don't require active management until an event of interest is detected. The incorrect answers: Line monitoring: This typically involves active management and immediate response to issues, so it doesn't meet Nayeli's requirements for a passive, after-the-fact analysis strategy. Motion detectors: While motion detectors are indeed passive, they don't typically record detailed information that allows for in-depth analysis after the fact. Security guard and dog: This security measure is very active and immediate; it doesn't facilitate in-depth, after-the-fact analysis.

Identifying the critical files and directories to be monitored: Before deploying a File Integrity Monitoring (FIM) system, it's crucial to determine which files and directories are critical and should be monitored. This involves identifying sensitive data, configuration files, system files, and other assets that, if altered, could impact the security or functionality of a system. By prioritizing these critical assets, organizations can ensure that the FIM system is focused on the most relevant and potentially vulnerable parts of their environment. The incorrect answers: Installing the FIM software: While it's essential to install the FIM software to begin monitoring, it's more important first to determine what files and directories are critical. Installing the software without this determination could lead to inefficiencies or missed vulnerabilities. Configuring the FIM system: Configuring the system is a subsequent step after determining which assets are critical and after the software is installed. Without first identifying what to monitor, configurations may not be optimized. Conducting a risk assessment: While risk assessments are vital in understanding and prioritizing threats, the direct first step in implementing an FIM system specifically involves identifying the files and directories for monitoring. Once we know which files needs to be monitored we can conduct a risk assessment on those assets.

Non-Disclosure Agreement: The most likely document that would prevent Mark from sharing his inside knowledge with a friend who works for a competitor is a Non-Disclosure Agreement (NDA). An NDA is a legal contract between an employee and an employer that explicitly prohibits the sharing of confidential information with unauthorized parties. NDAs are designed to protect sensitive business information and trade secrets, and violating an NDA can result in legal consequences. The incorrect answers: Acceptable Use Policy: An Acceptable Use Policy (AUP) typically outlines the proper usage of company resources, such as computers, networks, and internet services. While it might include clauses about protecting company information, it is not as specifically targeted to prevent the sharing of inside knowledge as an NDA. Non-Compete Agreement: A Non-Compete Agreement (NCA) restricts an employee from working for competitors or starting a competing business for a specified period after leaving the company. While it's related to competition, it doesn't specifically prohibit the sharing of knowledge while employed. Third-party Access Policy: A Third-Party Access Policy governs how external entities can access the company‚Äôs resources and what security controls are in place for such access. It is more relevant to vendors or partners than to employees and does not directly address the issue of an employee sharing information with friends.

Calculate the risk: When faced with a system change that conflicts with security standards, the best initial course of action is to calculate the risk associated with the proposed change. By assessing the potential impact and likelihood of security issues that could result from the change, decision-makers can make an informed choice about whether to proceed with the change, modify it, or reject it. This risk assessment will help determine the most appropriate response, which may include enforcing security standards, adjusting the change, or adding mitigating controls. The incorrect answers: Enforce the security standard: While security standards are crucial and should be enforced, immediately enforcing them without assessing the specific risk may disregard the potential benefits of the system owner‚Äôs request or the uniqueness of the situation. Make changes to the proposed system change to match the security standard: Making changes to align with security standards is important, but without first understanding the risk, those changes might be unnecessary or ineffective. Add mitigating controls to the system: Adding mitigating controls may be part of the solution after a risk assessment. However, without calculating the risk first, it's not possible to know which controls would be effective or necessary.

UEBA (User and Entity Behavior Analytics)
Most frequently accessed data: UEBA (User and Entity Behavior Analytics) is a cybersecurity process that takes note of the normal conduct of users and then detects any anomalous behavior or instances when they deviate from these patterns. The "most frequently accessed data" is a key indicator used by UEBA. The reason is that changes in the data a user regularly accesses can indicate potentially harmful actions. For instance, if a user who typically accesses a particular set of data suddenly starts accessing a different, more sensitive set of data, it could signify a compromised account or insider threat. UEBA systems detect such sudden changes in behavior and alert cybersecurity teams accordingly. 

Criminal investigation: This is the most common type of investigation, as it involves the process of collecting evidence and information to solve crimes. Law enforcement agencies, such as the police, are primarily responsible for conducting criminal investigations. These investigations aim to identify, apprehend, and prosecute offenders. The incorrect answers: Internal investigation: This is not as common as criminal investigations. It refers to the process where organizations or companies conduct inquiries into alleged misconduct, violations of policies, or regulatory issues within the organization. Although important, these investigations are typically limited to specific organizations and not as widespread as criminal investigations. Forensic investigation: While forensic investigation plays a significant role in solving crimes, it is not as common as criminal investigations. It refers to the application of scientific methods and techniques to gather evidence and analyze it in the context of legal proceedings. Forensic investigations usually occur within the scope of criminal investigations, making it a subset of the broader category. Environmental investigation: This type of investigation is less common compared to criminal investigations. It focuses on examining environmental issues, such as pollution, contamination, or natural resource damage. While essential, these investigations are typically carried out by environmental agencies or specialized units, and their occurrence is not as frequent as criminal investigations.

Build a physical barrier around the data center to deter floodwater. Physical barriers, such as flood walls or levees, are preventive controls that stop or minimize floodwater from entering the facility in the first place. This directly mitigates the physical risk of flooding, protecting both equipment and operations. Since relocation isn‚Äôt feasible, the next best solution is a structural control that prevents the hazard from impacting critical systems.



The incorrect answers:

Implement CCTV systems to monitor potential flood events: Monitoring provides awareness but does not prevent or reduce the impact of flooding. It‚Äôs a detective control, not a preventive one.

Develop policies and procedures for flood response: Policies are important but administrative controls; they guide action after a flood occurs, not mitigation.

Install a water detection system with automated water removal pumps: This is a corrective control that activates once flooding has already started, helping to reduce damage but not to prevent the event.

Redundant/Reciprocal/Mobile /Subscription/community  / hot/cold/warm sites
 In a disaster recovery context, a subscription site is a service provided by a third-party company that has servers and other computing resources available upon request. These servers are typically kept offline and are brought online in the event of a disaster. This allows an organization to quickly switch operations to the subscription site, thereby maintaining business continuity during the disaster. The incorrect answers: Reciprocal refers to an agreement between two organizations to host each other's backup hardware and data in the event of a disaster. This doesn't match the scenario described. Redundancy involves having duplicate hardware and data ready to take over in the event of a failure. While the servers described are in some sense a form of redundancy, the term doesn't adequately describe the situation where servers are kept offline and brought online only during a disaster. A mobile site, in the context of disaster recovery, usually refers to a portable temporary setup, like a trailer equipped with necessary hardware and communication links, which can be dispatched to the disaster-struck site. This doesn't match the situation described.

The most effective way to evaluate the success of a Configuration Management (CM) program is to check if the documentation is updated frequently. This means that the CM program is actively managing the items and maintaining a consistent record of configurations and changes. Up-to-date documentation suggests the ongoing management of the CM system, implying the program is functioning well in tracking and documenting changes, which is the primary goal of CM. The incorrect answers: The highest number of configuration items does not necessarily indicate an effective CM program. It could just mean that the organization is large or that it has many systems or components. A high number of configuration items could even be a problem if they are not effectively managed, leading to potential configuration errors and issues. The initial implementation of CM policies is an important step, but it doesn't serve as an indicator of ongoing effectiveness. It is more important to evaluate how these policies are being maintained and followed over time. The least amount of change requests does not necessarily mean a successful CM program. It may indicate a lack of change or innovation within the organization. An effective CM program should be capable of managing a high volume of changes efficiently, ensuring all changes are tracked and properly implemented. So the effectiveness should be measured by how well changes are managed, not by the number of changes.

 While the financial impact of a data breach is certainly important, it is not the most vital information for a Data Breach Investigation Report (DBIR). The primary goal of a DBIR is to understand the nature, scope, and cause of the data breach, to find out how it happened, what vulnerabilities were exploited, and how similar incidents can be prevented in the future. While the cost of the breach does provide some context about the seriousness of the incident, it is not as critical to the investigative process as the other factors. The incorrect answers: The extent of the breach is an important factor because it provides insight into how widespread the incident was and how much data was potentially compromised. This helps determine the scale of the issue and the potential level of damage caused by the breach. The sensitivity of the data involved is critical because it can indicate the potential impact of the breach on the affected individuals and the organization. The loss or exposure of sensitive data, such as personal information or trade secrets, can have serious ramifications, including financial loss, damage to reputation, and legal consequences. The number of affected individuals is an important factor because it indicates the scale of the breach in terms of potential harm to individuals. The greater the number of people affected, the more severe the consequences of the breach are likely to be. Knowing the number of affected individuals can also help organizations to manage their response and remediation efforts.

One of your employees has reported that their account was hacked, and important files were accessed without their permission. What is the process of gathering evidence to determine the cause of a security incident?
Network monitoring
Correct answer
Incident response
Your answer is incorrect
Access control
Administrative investigation
Overall explanation
The correct answer: Incident response is the process of identifying, investigating, and responding to security incidents. It includes stages such as preparation, detection and analysis, containment, eradication, recovery, and lessons learned. When a security incident, such as a hacked account, is reported, the incident response team investigates. They gather evidence from various sources such as logs, network traffic, and affected systems to understand the incident's cause and impact and ensure the threat is entirely eradicated and cannot reoccur. The incorrect answers: Network Monitoring: Network monitoring is a process where a system's network traffic is monitored to identify any slowdown or failure of the network. It involves using software and hardware tools to oversee and manage a network's operation, ensuring it performs at its best and preventing potential downtime. While network monitoring might help detect unusual network activity related to a security incident, it does not provide a complete investigative process like incident response. Administrative Investigation: This generally refers to an investigation into a breach of company policy or rules, often conducted by human resources or a similar department. It may be used in response to various issues, including harassment, discrimination, or workplace misconduct. While it can include security incidents if they involve employee misconduct, it is not focused solely on security issues. It does not provide the technical investigative process involved in incident response. Access Control: Access control limits access to a system or physical or virtual resources. It is a critical component in the security of information systems and networks, ensuring that only authorized individuals can access specific resources. While access control measures may be evaluated and improved after a security incident, they do not represent the process of gathering evidence and determining the cause of a security incident.



domain 7 
   In a chain of custody log, you should never record any modifications made to the original evidence. The chain of custody must maintain the integrity of the evidence; this means that the evidence should not be altered or tampered with in any way.
  
   Recovery Point Objective (RPO)
   Maximum Tolerable Downtime (MTD), 
   
   The type of information compromised in the breach: The most important factor to consider when reporting a breach is the type of information compromised. This is because different types of data have different legal, regulatory, and compliance requirements when it comes to breach reporting. For example, breaches involving personal identifiable information (PII), health information, or financial data are subject to specific laws and regulations. Understanding the type of data compromised can help assess the potential impact of the breach on individuals and the organization, guiding the subsequent response actions and mitigation strategies
  
  domain 7 - prevent ransomware by backup ??
implementing robust backup and recovery processes: This is the MOST effective way to prevent ransomware attacks. While it may not prevent the initial attack, having regular, secure backups can dramatically mitigate the effects of a ransomware attack by allowing a system or data to be restored without paying the ransom. It's crucial to ensure that backups are not connected to the systems they're backing up, as some ransomware can also infect connected backup systems

 domain name phishing
  cybersquatting and typo squatting threats.
  
  domain 7
  RAID 5: Block level striping with distributed parity, requires at least 3 disks. Combined speed with redundancy.
  
  domain 7
  Unallocated space refers to portions of the hard drive that are not currently assigned to hold data. An intelligent attacker might exploit this by marking a section of the drive as unallocated to conceal malicious software. This area isn't frequently scanned by standard antivirus or anti-malware software, making it a more likely hiding spot for malicious software. However, a comprehensive forensic analysis would include the scanning of unallocated space, increasing the chance of discovering any hidden threats. 

. Slack space is the area at the end of a file, up to the end of the final disk cluster used by that file. It could contain fragments of deleted or old files, including potentially malicious software, but it's not the most common place for a sophisticated perpetrator to hide malware due to its limited space and the fact that some forensic tools will also scan this area. Although the metadata area holds valuable information about system files and can be a useful source of evidence in a forensic investigation, it is not the most likely place to find hidden malware. An advanced attacker would likely avoid placing malware in this area as changes in the metadata can raise flags during system audits and analysis.

. Slack space is the area at the end of a file, up to the end of the final disk cluster used by that file. It could contain fragments of deleted or old files, including potentially malicious software, but it's not the most common place for a sophisticated perpetrator to hide malware due to its limited space and the fact that some forensic tools will also scan this area. Although the metadata area holds valuable information about system files and can be a useful source of evidence in a forensic investigation, it is not the most likely place to find hidden malware. An advanced attacker would likely avoid placing malware in this area as changes in the metadata can raise flags during system audits and analysis.

 Initiating containment procedures to prevent the threat from spreading to other systems is the most appropriate step after detecting an attack. Containment strategies, such as network segmentation, can isolate the affected systems and limit the damage caused by the attack. This is crucial in managing an APT, which often aims to move laterally through a network after gaining initial access. The incorrect answers: Additional intrusion detection systems may help detect further malicious activities in the network, but it's not the immediate next step after detecting an attack. The primary concern should be to contain the ongoing attack to prevent it from spreading to other systems. Although in some cases, powering down a system might be a valid containment strategy, doing so without attempting to capture more details about the attack might lead to the loss of valuable forensic data. Also, in the case of an APT, an immediate shutdown might alert the attacker, who might then alter their tactics, making future detection and mitigation more difficult. Internal communication is an important part of incident management, but it's not the immediate next step after detecting an attack. Such a communication should also be carefully planned and executed to avoid unnecessary panic and confusion among employees. The immediate focus should be on technical measures to contain the threat.

In CISSP Disaster Recovery (DR) context, MTD and MAD are easy to mix up‚Äîbut they answer different survival questions.

üîπ MTD ‚Äî Maximum Tolerable Downtime
Question it answers:
‚ÄúHow long can this business process be down before the organization suffers unacceptable damage?‚Äù
Key points:
Business-driven
Set by senior management / BIA
Includes all impacts: financial loss, reputation, legal, safety
Defines the upper limit for recovery
üëâ Think: absolute pain threshold
üîπ MAD ‚Äî Maximum Allowable Downtime
Question it answers:
‚ÄúWhat downtime limit can IT realistically design recovery solutions to meet?‚Äù
Key points:
IT / technical-driven
Constrained by technology, cost, and complexity
Must always be ‚â§ MTD
Used to design DR strategy and controls
üëâ Think: engineering constraint
üîÅ Relationship (EXAM GOLD)
MAD ‚â§ MTD


If MAD > MTD ‚Üí ‚ùå Business fails (IT can‚Äôt meet business needs)

üîπ Where RTO fits (for exam clarity)

RTO (Recovery Time Objective) is usually set at or below MAD
RTO is what DR plans are actually tested against
RTO ‚â§ MAD ‚â§ MTD

üß† CISSP Memory Trick

MTD = Management Tolerance

MAD = Admin (IT) Design Limit

üìù Quick Example

Online trading platform
MTD: 2 hours (after that ‚Üí regulatory + financial disaster)
MAD: 90 minutes (best IT can guarantee)
RTO: 60 minutes (chosen target)

‚úÖ Passes CISSP logic

‚ö†Ô∏è Common CISSP Traps

MTD is NOT set by IT
MAD is NOT a business decision
You never choose a solution where MAD exceeds MTD


Your company has recently experienced significant data loss due to a ransomware attack, and you want to ensure that this does not happen again. You decide to implement a 3-2-1 backup strategy to safeguard against future threats. Which of the following best describes the 3-2-1 backup strategy?
Having two copies of data on two different servers in the same location
Having three copies of data on three different servers in the same location
Your answer is correct
Having three copies of data on three different servers in different locations
Having one copy of data on a single server in a remote location
Overall explanation
The correct answer: Having three copies of data on three different servers in different locations. The 3-2-1 backup strategy suggests having: Three total copies of your data: 1 primary copy and 2 backups. The data should be kept on at least two different types of media or platforms, ensuring against a single medium failure. One of these copies should be stored off-site, ensuring data security in case of local physical events like fires, floods, or other disasters. This principle is not strictly about having the data on three different servers, but the key idea is redundancy and geographical dispersion. The option "Having three copies of data on three different servers in different locations" captures this idea best among the given options. The incorrect answers: Having three copies of data on three different servers in the same location: This provides redundancy in terms of multiple copies, having all copies in the same location doesn't safeguard against local physical threats like fires or natural disasters. Having two copies of data on two different servers in the same location: This choice offers some level of redundancy but lacks the robustness of the 3-2-1 strategy. Moreover, it again doesn't protect against localized physical disasters since the copies are in the same location. Having one copy of data on a single server in a remote location: This doesn't follow the 3-2-1 principle at all. It lacks redundancy and leaves the data at risk if anything happens to that single remote server.


: From the perspective of the organization, Sulaima is addressing environmental disasters when designing specifications for ISP outages in the Disaster Recovery Plan (DRP). In this context, environmental disasters are disruptions to the operational environment that impact the organization's ability to function normally. An ISP outage, no matter the cause, affects the operational environment of Sulaima's organization by disrupting their connectivity, hence it is regarded as an environmental disaster. The incorrect answers: Although natural disasters like hurricanes, earthquakes, or severe weather conditions could theoretically lead to ISP outages, in this specific context, "environmental" is more suitable. While the two categories can overlap, natural disasters refer more broadly to significant, large-scale events caused by environmental processes, whereas environmental disasters in this context focus more on operational or infrastructure issues. While ISP outages can be caused by man-made disasters such as cyber attacks or network misconfigurations, in this context, the focus is on environmental causes like physical damage to infrastructure. Considering ISP outages as man-made disasters would not be the most accurate categorization in this instance. While a comprehensive DRP would cover natural, man-made, and environmental disasters, when preparing specifically for ISP outages due to environmental causes, the primary focus would be on environmental disasters.

What is the MOST effective way to onboard new employees in regard to security?
Your answer is incorrect
Conducting a thorough background check
Correct answer
Providing hands-on training and guidance from a security expert
Providing them with a list of policies and procedures to read through
Giving them access to all systems and resources immediately
Overall explanation
The correct answer: Providing hands-on training and guidance from a security expert: This is the most effective way to onboard new employees in regards to security. It ensures they understand the organization's security policies and procedures, know how to follow them, and understand the consequences of not following them. Hands-on training can include real-world examples and interactive sessions, which are often more effective than simply reading through documents. The incorrect answers: Providing them with a list of policies and procedures to read through: This is a necessary part of the onboarding process, it is not the most effective way to ensure new employees understand and follow the organization's security policies. Reading through policies and procedures may not provide the context or practical knowledge that hands-on training would. Conducting a thorough background check: Conducting a background check is an important part of the hiring process, it is not part of the onboarding process and doesn't directly contribute to the new employee's understanding of the organization's security policies and procedures. Giving them access to all systems and resources immediately: This could pose a security risk if the new employee is not yet familiar with the organization's security policies and procedures. Access to systems and resources should be granted based on the principle of least privilege, which means employees should only have access to the information and resources necessary for their job functions.

Which of the following is the MOST effective approach for conducting forensics in the cloud?
Your answer is incorrect
Outsourcing the forensic analysis to a third-party vendor
Conducting a full-scale data breach investigation
Using traditional forensic tools and techniques
Correct answer
Implementing cloud-specific forensic tools and techniques
Overall explanation
The correct answer: In order to effectively conduct forensics in the cloud, it is important to use tools and techniques that are specifically designed for the unique challenges and complexities of the cloud environment. Traditional forensic tools and techniques may not be sufficient for conducting an effective investigation in the cloud, and outsourcing the analysis to a third-party vendor can introduce additional security risks. A full-scale data breach investigation may not be necessary for conducting forensics in the cloud, as it may not be relevant to the specific forensic goal. The incorrect answers: While traditional forensic tools and techniques may be effective for conducting investigations in on-premises environments, they may not be sufficient for conducting investigations in the cloud. The cloud environment introduces additional complexities and challenges that require specialized tools and techniques. A full-scale data breach investigation may not be necessary for conducting forensics in the cloud. Forensics in the cloud may focus on specific goals, such as identifying the source of a security incident or determining the extent of data exfiltration, rather than a broad data breach investigation. While outsourcing the forensic analysis to a third-party vendor may provide access to specialized expertise, it can also introduce additional security risks. The vendor may not have the same level of security controls and policies as the organization, and may not be subject to the same regulatory requirements. It is important to carefully evaluate the risks and benefits of outsourcing forensics in the cloud.